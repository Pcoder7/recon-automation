name: Parallel Subdomain Enumeration and Live Host Check

on:
  schedule:
    - cron: "0 10 * * *"  # Runs every day at 10:00 AM UTC
  workflow_dispatch:

permissions:
  contents: write

env:
  PDCP_KEY: ${{ secrets.PDCP_API_KEY }}  

jobs:
  generate_matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set_matrix.outputs.matrix }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0        

      - name: Generate Matrix from domains.txt
        id: set_matrix
        run: |
          if [ ! -f domains.txt ]; then
            echo "domains.txt file not found!"
            exit 0
          fi
          # Create a JSON array from non-empty lines in domains.txt
          matrix=$(jq -R -s -c 'split("\n") | map(select(length > 0))' domains.txt)
          echo "Matrix: $matrix"
          echo "matrix=$matrix" >> $GITHUB_OUTPUT
          
  subdomain_scan:
    needs: generate_matrix
    runs-on: ubuntu-latest
    container:
      # Use the exact same container for consistency with the primary account
      image: ghcr.io/pcoder7/spider-puredns-actions:latest
      credentials:
        username: ${{ secrets.GHCR_USER }}
        password: ${{ secrets.GHCR_TOKEN }}      
    strategy:
      fail-fast: false
      matrix:
        domain: ${{ fromJson(needs.generate_matrix.outputs.matrix) }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          # Fetch full Git history so previous commits are available for comparison
          fetch-depth: 0   
          
      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.23'

      - name: Cache Go modules & binaries
        uses: actions/cache@v3
        with:
          path: |
            $HOME/go/pkg/mod
            ~/.cache/go-build
            $HOME/go/bin
          key: ${{ runner.os }}-go-cache-${{ github.ref_name }}
          restore-keys: |
            ${{ runner.os }}-go-cache-
         
      
      - name: Install Tools
        run: |
          # Installing Jq

          if ! command -v jq >/dev/null; then
            echo "Installing jq…"
            apt install jq
          else
            echo "Jq already installed"
          fi   
          # Installing smap
          if ! command -v smap >/dev/null; then
            echo "Installing smap…"
            go install -v github.com/s0md3v/smap/cmd/smap@latest
          else
            echo "smap already installed"
          fi    

          # Installing inscope
          if ! command -v inscope >/dev/null; then
            echo "Installing inscope…"
            go install -v github.com/tomnomnom/hacks/inscope@latest
          else
            echo "inscope already in installed"
          fi    
          
          # Installing Chaos-client
          if ! command -v chaos >/dev/null; then
            echo "Installing Chaos…"
            go install -v github.com/projectdiscovery/chaos-client/cmd/chaos@latest
          else
            echo "Chaos already in installed"
          fi    
          
          
          if ! command -v anew >/dev/null; then
            echo "Installing anew…"
            go install -v github.com/tomnomnom/anew@latest
          else
            echo "anew already in installed"
          fi

          if ! command -v shrewdeye >/dev/null; then
            echo "Installing Shrewdeye…"
            go install -v github.com/omkar7505/shrewdeye@latest
          else
            echo "shrewdeye already in installed"
          fi
          
          pip3 install --no-cache-dir ipaddress
          
          echo "$HOME/go/bin" >> $GITHUB_PATH

      - name: Ensure Node + phantomjs available
        shell: bash
        run: |
          
          echo "Installing Node (via actions/setup-node is preferred). Falling back to apt if needed."
          # If running inside GH Actions prefer actions/setup-node; fallback:
          if ! command -v node >/dev/null 2>&1; then
            curl -fsSL https://deb.nodesource.com/setup_18.x | bash -
            apt-get update -y
            apt-get install -y nodejs
          fi
          node --version
          npm --version
    
          # Install phantomjs via npm prebuilt (global)
          npm install -g --unsafe-perm phantomjs-prebuilt@2.1.16 || true
          echo "phantomjs path: $(which phantomjs || echo 'not found')"
          phantomjs --version || echo "phantomjs not available"     

      - name: Install and Configure Sudomy
        shell: bash
        run: |
          echo "==== Installing Sudomy ===="
          
          # Store current directory
          ORIGINAL_DIR=$(pwd)
          echo "Current directory: ${ORIGINAL_DIR}"
          
          # Clone Sudomy to a known location
          SUDOMY_INSTALL_DIR="/opt/sudomy"
          
          if [ ! -d "${SUDOMY_INSTALL_DIR}" ]; then
            git clone --recursive https://github.com/screetsec/Sudomy.git "${SUDOMY_INSTALL_DIR}"
            cd "${SUDOMY_INSTALL_DIR}"
            
            echo "Installing Python requirements..."
            python3 -m pip install -r requirements.txt
            
            echo "Installing system dependencies..."
            apt-get update
            apt-get install -y jq chromium parallel || true
            

            echo "Node version: $(node --version 2>/dev/null || echo 'node not found')"
            echo "NPM version: $(npm --version 2>/dev/null || echo 'npm not found')"
            echo "nmap: $(which nmap || true) $(nmap --version 2>/dev/null | head -n1 || true)"
            echo "chromium-browser: $(which chromium-browser || true)"

            
            # Make sudomy executable
            chmod +x "${SUDOMY_INSTALL_DIR}/sudomy"
            chown -R "$(whoami)":"$(whoami)" "${SUDOMY_INSTALL_DIR}"
            # Return to original directory
            cd "${ORIGINAL_DIR}"
            echo "Returned to: $(pwd)"
            
            # Add to PATH
            echo "${SUDOMY_INSTALL_DIR}" >> $GITHUB_PATH
            
            # Create output directory if it doesn't exist
            mkdir -p "${SUDOMY_INSTALL_DIR}/output"
            
            echo "Sudomy installed successfully at: ${SUDOMY_INSTALL_DIR}"
          else
            echo "Sudomy already installed at: ${SUDOMY_INSTALL_DIR}"
          fi
          
          # Verify installation (from original directory)
          echo "==== Verifying Sudomy Installation ===="
          echo "Current working directory: $(pwd)"
          ls -la "${SUDOMY_INSTALL_DIR}" || true
          
          if [ -f "${SUDOMY_INSTALL_DIR}/sudomy" ]; then
            echo "Sudomy executable found"
            echo "Sudomy location: ${SUDOMY_INSTALL_DIR}/sudomy"
          else
            echo "WARNING: Sudomy executable not found!"
          fi
          
          # Check if output directory exists
          if [ -d "${SUDOMY_INSTALL_DIR}/output" ]; then
            echo "Sudomy output directory confirmed at: ${SUDOMY_INSTALL_DIR}/output"
          else
            echo "WARNING: Output directory not found, creating it..."
            mkdir -p "${SUDOMY_INSTALL_DIR}/output"
          fi
          ls -la "${SUDOMY_INSTALL_DIR}" || true
          # Store the installation path for later use
          echo "SUDOMY_INSTALL_DIR=${SUDOMY_INSTALL_DIR}" >> $GITHUB_ENV


      - name: Install and Configure theHarvester
        shell: bash
        run: |
          echo "==== Installing theHarvester ===="
          
          # Store current directory
          ORIGINAL_DIR=$(pwd)
          echo "Current directory: ${ORIGINAL_DIR}"
          
          # Define installation directory
          THEHARVESTER_INSTALL_DIR="/opt/theHarvester"
          
          if [ ! -d "${THEHARVESTER_INSTALL_DIR}" ]; then
            echo "Installing UV package manager..."
            # Install UV (modern Python package manager recommended by theHarvester)
            curl -LsSf https://astral.sh/uv/install.sh | sh
            
            # Source the environment file created by UV installer
            if [ -f "$HOME/.local/bin/env" ]; then
              source $HOME/.local/bin/env
              echo "UV environment sourced from $HOME/.local/bin/env"
            else
              # Fallback: add to PATH manually
              export PATH="$HOME/.local/bin:$PATH"
              echo "UV added to PATH manually"
            fi
            
            # Verify UV is available
            echo "Checking UV installation..."
            which uv || echo "UV not found in PATH"
            uv --version || echo "UV command failed"
            
            echo "Cloning theHarvester repository..."
            git clone https://github.com/laramies/theHarvester "${THEHARVESTER_INSTALL_DIR}"
            
            cd "${THEHARVESTER_INSTALL_DIR}"
            
            echo "Installing dependencies with UV..."
            # Install dependencies and create virtual environment
            uv sync
            
            # Return to original directory
            cd "${ORIGINAL_DIR}"
            echo "Returned to: $(pwd)"
            
            # Create a wrapper script to run theHarvester easily
            
            cat > /usr/local/bin/theHarvester << 'EOF'
          #!/bin/bash
          export PATH="$HOME/.local/bin:$PATH"
          cd /opt/theHarvester
          uv run theHarvester "$@"
          cd ../..
          EOF
            
            chmod +x /usr/local/bin/theHarvester
            
            echo "theHarvester installed successfully at: ${THEHARVESTER_INSTALL_DIR}"
          else
            echo "theHarvester already installed at: ${THEHARVESTER_INSTALL_DIR}"
          fi
          
          # Verify installation
          echo "==== Verifying theHarvester Installation ===="
          ls -la "${THEHARVESTER_INSTALL_DIR}" || true
          
          if [ -f "${THEHARVESTER_INSTALL_DIR}/theHarvester.py" ]; then
            echo "theHarvester.py found"
          else
            echo "WARNING: theHarvester.py not found!"
          fi
          
          # Test theHarvester
          echo "Testing theHarvester..."
          theHarvester -h | head -n 5 || echo "theHarvester test failed, but may work later"
          
          # Store the installation path for later use
          echo "THEHARVESTER_INSTALL_DIR=${THEHARVESTER_INSTALL_DIR}" >> $GITHUB_ENV
    
      - name: Install interlace tool
        shell: bash
        run: |
          python3 --version
          git clone https://github.com/codingo/Interlace.git
          cd Interlace
          python3 -m pip install -r requirements.txt
          pip3 install .
          python3 Interlace/interlace.py -h
          cd ..

      - name: Run Subdomain Enumeration (interlace + bbot) for ${{ matrix.domain }}
        shell: bash
        env:
          DOMAIN: ${{ matrix.domain }}
        run: |
          
          echo "==== ENV ===="
          echo "PWD: $(pwd)"
          echo "USER: $(whoami)"
          echo "HOME: $HOME"
          echo "DOMAIN: ${DOMAIN}"
          echo "==== CHECK BBOT ===="
          
          if command -v bbot >/dev/null 2>&1; then
            echo "bbot -> $(which bbot)"
            bbot --version || true
          else
            echo "bbot not found in PATH. Ensure container contains bbot or adjust PATH."
          fi


          TMP_ONEFOR="$(mktemp)"
          
          OUTDIR="results/${{ matrix.domain }}"
          JSONFILE="${OUTDIR}/oneforall.json"
          ONEFORALL_TXT="${OUTDIR}/oneforall.txt"
          EXTERNAL_TX="$(mktemp)"
          EXTERNAL_FINAL="${OUTDIR}/external.txt"
          TARGET="${OUTDIR}/all_subdomains.txt"
          WORKSPACE="${GITHUB_WORKSPACE:-$(pwd)}"
          ORIGINAL_DIR="${ORIGINAL_DIR:-${WORKSPACE}}"
          WORK_RESULTS_DIR="${WORKSPACE}/results/${DOMAIN}"
          mkdir -p "${WORK_RESULTS_DIR}"
          echo "Workspace results dir: ${WORK_RESULTS_DIR}"
          
          echo "==== run interlace ===="
          mkdir -p results/"${DOMAIN}"
          interlace \
            -t "${DOMAIN}" \
            -threads 3 \
            -cL cli.txt \
            -o results/"${DOMAIN}" \
            -v || echo "interlace returned $?"

          echo "interlace outputs:"
          ls -la results/"${DOMAIN}" || true

          # --- External: download and normalize (fixed sed input) ---
          mkdir -p "$OUTDIR"
          REMOTE_URL="https://raw.githubusercontent.com/rix4uni/BugBountyData/refs/heads/main/data/${{ matrix.domain }}.txt"
          if curl -fsSL "$REMOTE_URL" -o "$EXTERNAL_TX"; then
            sed -E "s#^https?://##I; s/^[*.]+//; s/[.]+$//; s/^[[:space:]]+//; s/[[:space:]]+$//" "$EXTERNAL_TX" | grep -P "^(?=.{1,253}$)(?:[A-Za-z0-9](?:[A-Za-z0-9-]{0,61}[A-Za-z0-9])?\.)+[A-Za-z]{2,63}$" --color=never \
              | sort -u > "$EXTERNAL_FINAL" || true
          else
            : > "$EXTERNAL_FINAL"
          fi
          
          rm -f "$EXTERNAL_TX"
          echo "external lines: $(wc -l < "$EXTERNAL_FINAL")"        

          
          echo "==== Collecting Sudomy results ===="
          
          # Use the environment variable set during installation
          SUDOMY_INSTALL_DIR="${SUDOMY_INSTALL_DIR:-/opt/sudomy}"
          SUDOMY_OUTPUT_BASE="${SUDOMY_INSTALL_DIR}/output"
          
          echo "Sudomy installation directory: ${SUDOMY_INSTALL_DIR}"
          echo "Sudomy output base directory: ${SUDOMY_OUTPUT_BASE}"
          
          # Make sure required binaries exist (install if missing)
          if ! command -v nmap >/dev/null 2>&1; then
            echo "nmap missing -> attempting install (apt-get)"
            apt-get update -y
            apt-get install -y nmap jq nodejs npm || true
          fi
          
          # PhantomJS fallback (best-effort, apt often has no candidate)
          if ! command -v phantomjs >/dev/null 2>&1; then
            echo "phantomjs not found; attempting npm install -g phantomjs-prebuilt (best-effort)"
            npm i -g phantomjs-prebuilt || true
          fi
          
          # Ensure Sudomy repo is present and contains expected files; re-clone if incomplete
          if [ ! -d "${SUDOMY_INSTALL_DIR}" ] || [ ! -f "${SUDOMY_INSTALL_DIR}/sudomy" ] || [ ! -f "${SUDOMY_INSTALL_DIR}/sudomy.api" ]; then
            echo "Sudomy appears missing or incomplete at ${SUDOMY_INSTALL_DIR} -> (re)cloning"
            rm -rf "${SUDOMY_INSTALL_DIR}" || true
          fi
          
          # Short debug listing (keeps logs useful)
          echo "Listing sudomy directory (top):"
          ls -la "${SUDOMY_INSTALL_DIR}" | sed -n '1,200p' || true
          echo "sudomy.api present? $( [ -f "${SUDOMY_INSTALL_DIR}/sudomy.api" ] && echo yes || echo no )"
          echo "which nmap: $(which nmap || true)"
          
          # Run sudomy from its directory, guaranteeing return using pushd/popd
          pushd "${SUDOMY_INSTALL_DIR}" >/dev/null || ( echo "Failed to enter ${SUDOMY_INSTALL_DIR}" && true )
          
          # Prefer direct python invocation if sudomy.api exists (more reliable)
          if [ -f "./sudomy.api" ]; then
            echo "Running: python3 ./sudomy.api -d ${DOMAIN} --no-probe"
            python3 ./sudomy.api -d "${DOMAIN}" --no-probe || true
          else
            echo "Running: ./sudomy -d ${DOMAIN} --no-probe"
            chmod +x ./sudomy || true
            ./sudomy -d "${DOMAIN}" --no-probe || true
          fi
          
          popd >/dev/null || true
          
          # Find Sudomy output: today format and fallback search across output dir
          TODAY=$(date +"%m-%d-%Y")
          SUDOMY_DOMAIN_DIR="${SUDOMY_OUTPUT_BASE}/${TODAY}/${DOMAIN}"
          echo "Checking Sudomy output at: ${SUDOMY_DOMAIN_DIR}/subdomains.txt"
          
          if [ -f "${SUDOMY_DOMAIN_DIR}/subdomains.txt" ]; then
            sed 's/^\*\.//' "${SUDOMY_DOMAIN_DIR}/subdomains.txt" \
              | sed 's/^[[:space:]]*//; s/[[:space:]]*$//' \
              | grep -P "^(?=.{1,253}$)(?:[A-Za-z0-9](?:[A-Za-z0-9-]{0,61}[A-Za-z0-9])?\.)+[A-Za-z]{2,63}$" --color=never \
              > "${WORK_RESULTS_DIR}/sudomy.txt" || true
          
            echo "Sudomy results copied to workspace: $(wc -l < "${WORK_RESULTS_DIR}/sudomy.txt" || echo 0) subdomains"
          else
            echo "Sudomy subdomains.txt not found at expected path"
            echo "Listing ${SUDOMY_OUTPUT_BASE} top-level (short):"
            ls -la "${SUDOMY_OUTPUT_BASE}" 2>/dev/null | sed -n '1,200p' || true
          
            FOUND_SUDOMY=$(find "${SUDOMY_OUTPUT_BASE}" -type f -path "*/${DOMAIN}/subdomains.txt" -print -quit 2>/dev/null || true)
            if [ -n "${FOUND_SUDOMY}" ]; then
              echo "Found Sudomy output at: ${FOUND_SUDOMY} -> copying"
              sed 's/^\*\.//' "${FOUND_SUDOMY}" \
                | sed 's/^[[:space:]]*//; s/[[:space:]]*$//' \
                | grep -P "^(?=.{1,253}$)(?:[A-Za-z0-9](?:[A-Za-z0-9-]{0,61}[A-Za-z0-9])?\.)+[A-Za-z]{2,63}$" --color=never \
                > "${WORK_RESULTS_DIR}/sudomy.txt" || true
          
              echo "Copied Sudomy results: $(wc -l < "${WORK_RESULTS_DIR}/sudomy.txt" || echo 0)"
            else
              echo "No Sudomy results found under ${SUDOMY_OUTPUT_BASE}. Creating empty sudomy.txt in workspace"
              touch "${WORK_RESULTS_DIR}/sudomy.txt" || ( echo "Failed to touch ${WORK_RESULTS_DIR}/sudomy.txt" && ls -la "$(dirname "${WORK_RESULTS_DIR}")" || true )
            fi
          fi
          
          echo "==== Completed hardened Sudomy run ===="

          echo "======= Running Harvester ========="
          mkdir -p "results/${DOMAIN}"
          THEHARVEST_JSON="results/${DOMAIN}/theharvester.json"
          
          theHarvester -d "${DOMAIN}" -b all -f "${THEHARVEST_JSON}" --quiet 

          echo "Filtering the Harvester json file"
          jq -r '.hosts | map(select(type=="string") | split(":")[0]) | unique[]' "${THEHARVEST_JSON}" \
            | sed 's/^\*\.//' \
            | sed 's/^[[:space:]]*//; s/[[:space:]]*$//' \
            | grep -P "^(?=.{1,253}$)(?:[A-Za-z0-9](?:[A-Za-z0-9-]{0,61}[A-Za-z0-9])?\.)+[A-Za-z]{2,63}$" --color=never \
            > "results/${DOMAIN}/theHarvester.txt" || true

          echo "====== Running assetfinder ===========" 

          assetfinder --subs-only "${DOMAIN}" \
            | sed 's/^\*\.//' \
            | sed 's/^[[:space:]]*//; s/[[:space:]]*$//' \
            | grep -P "^(?=.{1,253}$)(?:[A-Za-z0-9](?:[A-Za-z0-9-]{0,61}[A-Za-z0-9])?\.)+[A-Za-z]{2,63}$" --color=never \
            > "results/${DOMAIN}/assetfinder.txt" || true   

          echo "===== Running Chaos Projectdiscovery =========== "

          echo "Debug: check PDCP_KEY is present (length only)"
          if [ -z "${PDCP_KEY:-}" ]; then
            echo "PDCP_KEY is MISSING in this environment"
          else
            # print length only (safe)
            echo "PDCP_KEY present, length=$(printf '%s' "$PDCP_KEY" | wc -c)"
          fi
          chaos -d "${{ matrix.domain }}" -o "$OUTDIR/chaos.txt" -key "${PDCP_KEY}" -silent | sed 's/^\*\.//' | sed 's/^[[:space:]]*//; s/[[:space:]]*$//' | grep -P "^(?=.{1,253}$)(?:[A-Za-z0-9](?:[A-Za-z0-9-]{0,61}[A-Za-z0-9])?\.)+[A-Za-z]{2,63}$" --color=never || true

          # --- oneforall: extract subdomain entries (fixed jq usage) ---
          echo "====== Collect OneForAll results ===========" 
          if [[ -s "$JSONFILE" ]]; then
            jq -r '.. | objects | .subdomain? // empty' "$JSONFILE" \
              | sed -E "s#^https?://##I; s/^[*.]+//; s/[.]+$//; s/^[[:space:]]+//; s/[[:space:]]+$//" \
              | grep -E '^[a-z0-9]([a-z0-9-]*\.)+[a-z]{2,}$' --color=never \
              | sort -u > "$TMP_ONEFOR" || true
          else
            : > "$TMP_ONEFOR"
          fi
          mv -f "$TMP_ONEFOR" "$ONEFORALL_TXT"
          chmod 644 "$ONEFORALL_TXT"
          echo "oneforall lines: $(wc -l < "$ONEFORALL_TXT")"

          # merge interlace outputs if present
          if [ -f results/"${DOMAIN}"/subfinder.txt ] || [ -f results/"${DOMAIN}"/assetfinder.txt ] || [ -f results/"${DOMAIN}"/amass.txt ]; then
            cat results/"${DOMAIN}"/subfinder.txt \
              results/"${DOMAIN}"/assetfinder.txt \
              results/"${DOMAIN}"/amass.txt \
              results/"${DOMAIN}"/shrewdeye.txt \
              results/"${DOMAIN}"/findomain.txt \
              "$ONEFORALL_TXT" 2>/dev/null \
              | inscope --scope .scope \
              | sort -u > results/"${DOMAIN}"/all_subdomains_interlace.txt || true             
            
            echo "all_subdomains_interlace.txt lines: $(wc -l < results/${DOMAIN}/all_subdomains_interlace.txt || echo 0)"
          else
            echo "No known interlace subdomain files found to combine."
          fi
           
          echo "==== run BBOT (passive subdomain-enum) ===="
          mkdir -p results/"${DOMAIN}"/bbot-output
          chmod -R u+rwX results/"${DOMAIN}"

          BBOT_OUTPUT_DIR="results/${DOMAIN}/bbot-output"
          BBOT_SCANNAME="bbot_${DOMAIN}_scan"
          SCAN_DIR="${BBOT_OUTPUT_DIR}/${BBOT_SCANNAME}"

          # Run BBOT (passive-only), exclude massdns, asn, wappalyzer and aggressive modules; force output-dir & name
          bbot -t "${DOMAIN}" \
            -p subdomain-enum \
            -rf passive \
            -em baddns baddns_direct baddns_zone asn wappalyzer builtwith \
            -ef aggressive \
            -y \
            -o "${BBOT_OUTPUT_DIR}" \
            -n "${BBOT_SCANNAME}" || echo "bbot exited with code $?"

          echo "Listing explicit BBOT output directory:"
          ls -la "${BBOT_OUTPUT_DIR}" || true

          echo "Listing BBOT default scans dir (~/.bbot/scans) in case BBOT wrote there:"
          ls -la "$HOME/.bbot/scans" || true
          ls -lt "$HOME/.bbot/scans" | head -n 5 || true

          # If BBOT wrote to default location, copy latest into workspace results
          if [ -d "$HOME/.bbot/scans" ] && [ "$(ls -A "$HOME/.bbot/scans" 2>/dev/null || true)" != "" ]; then
            LATEST_DIR=$(ls -1t "$HOME/.bbot/scans" | head -n1 || true)
            if [ -n "${LATEST_DIR}" ]; then
              echo "Copying latest default BBOT scan '$LATEST_DIR' -> results/${DOMAIN}/bbot-default-copy"
              mkdir -p results/"${DOMAIN}"/bbot-default-copy
              cp -a "$HOME/.bbot/scans/${LATEST_DIR}/." results/"${DOMAIN}"/bbot-default-copy/ || true
            fi
          fi

          # --- Use find to grab subdomains.txt files from the BBOT scan dir(s) and create exactly one file ----
          mkdir -p results/"${DOMAIN}"
          # Prefer explicit scan dir produced by -o -n
          if [ -d "${SCAN_DIR}" ]; then
            echo "Found explicit scan dir: ${SCAN_DIR}"
            # Concatenate any subdomains.txt found under the scan dir into one file
            find "${SCAN_DIR}" -type f -name 'subdomains.txt' -exec cat {} + > results/"${DOMAIN}"/bbot-subdomains.txt || true
          else
            echo "Explicit scan dir ${SCAN_DIR} not found. Searching under ${BBOT_OUTPUT_DIR} ..."
            find "${BBOT_OUTPUT_DIR}" -type f -name 'subdomains.txt' -exec cat {} + > results/"${DOMAIN}"/bbot-subdomains.txt || true
          fi

          # If nothing found in explicit output-dir, check default BBOT location copy
          if [ ! -s results/"${DOMAIN}"/bbot-subdomains.txt ] && [ -d results/"${DOMAIN}"/bbot-default-copy ]; then
            echo "No subdomains in explicit output-dir; checking bbot-default-copy ..."
            find results/"${DOMAIN}"/bbot-default-copy -type f -name 'subdomains.txt' -exec cat {} + > results/"${DOMAIN}"/bbot-subdomains.txt || true
          fi

          if [ -s results/"${DOMAIN}"/bbot-subdomains.txt ]; then
            echo "BBOT subdomains collected: $(wc -l < results/${DOMAIN}/bbot-subdomains.txt)"
          else
            echo "No bbot-subdomains.txt created or file is empty."
          fi

          # --- Clean up BBOT scan folder: keep only subdomains.txt files (user requested minimal files) ---
          if [ -d "${SCAN_DIR}" ]; then
            echo "Cleaning up ${SCAN_DIR}: deleting all files except subdomains.txt"
            find "${SCAN_DIR}" -type f ! -name 'subdomains.txt' -delete || true
            # remove empty directories left behind
            find "${SCAN_DIR}" -type d -empty -delete || true
            echo "Post-cleanup listing for ${SCAN_DIR}:"
            ls -la "${SCAN_DIR}" || true
          fi

          # Also clean up any copies made
          if [ -d results/"${DOMAIN}"/bbot-default-copy ]; then
            echo "Cleaning up bbot-default-copy: deleting files except subdomains.txt"
            find results/"${DOMAIN}"/bbot-default-copy -type f ! -name 'subdomains.txt' -delete || true
            find results/"${DOMAIN}"/bbot-default-copy -type d -empty -delete || true
            ls -la results/"${DOMAIN}"/bbot-default-copy || true
          fi

          # --- Combine BBOT subdomains with interlace combined file into a single all_subdomains.txt ----
          INTERLACE_FILE=results/"${DOMAIN}"/all_subdomains_interlace.txt
          BBOT_FILE=results/"${DOMAIN}"/bbot-subdomains.txt
          OUT_FILE=results/"${DOMAIN}"/all_subdomains.txt

          echo "Combining files:"
          echo "  Interlace: ${INTERLACE_FILE} (exists: $( [ -f "${INTERLACE_FILE}" ] && echo yes || echo no ))"
          echo "  BBOT:      ${BBOT_FILE} (exists: $( [ -f "${BBOT_FILE}" ] && echo yes || echo no ))"

          if [ -f "${INTERLACE_FILE}" ] && [ -f "${BBOT_FILE}" ]; then
            cat "${INTERLACE_FILE}" "${BBOT_FILE}" "$OUTDIR/chaos.txt" "results/${DOMAIN}/assetfinder.txt" "results/${DOMAIN}/theHarvester.txt" "results/${DOMAIN}/sudomy.txt" "$EXTERNAL_FINAL" | sort -u > "${OUT_FILE}"
          elif [ -f "${INTERLACE_FILE}" ]; then
            sort -u "${INTERLACE_FILE}" > "${OUT_FILE}"
          elif [ -f "${BBOT_FILE}" ]; then
            sort -u "${BBOT_FILE}" "$OUTDIR/chaos.txt" "results/${DOMAIN}/assetfinder.txt" "results/${DOMAIN}/theHarvester.txt" "results/${DOMAIN}/sudomy.txt" "$EXTERNAL_FINAL" > "${OUT_FILE}"
          else
            echo "# no subdomains found from interlace or bbot" > "${OUT_FILE}"
          fi

          echo "Final all_subdomains.txt lines: $(wc -l < "${OUT_FILE}" || echo 0)"
          echo "Final listing results/${DOMAIN}:"
          ls -la results/"${DOMAIN}" || true
          rm "results/${DOMAIN}/oneforall.json" 
          rm -r "results/${DOMAIN}/bbot-output"

      - name: Upload all results for ${{ matrix.domain }}
        uses: actions/upload-artifact@v4
        with:
          name: recon-results-${{ matrix.domain }}
          path: |
            results/${{ matrix.domain }}
          retention-days: 1

  commit_results:
    name: Commit All Recon Results
    # This job runs after all parallel scan jobs are finished.
    needs: subdomain_scan
    # 'if: always()' ensures we commit results from successful scans even if some scans failed.
    if: always()
    runs-on: ubuntu-latest
    container:
      # Use the same container to ensure tools like 'anew' are available.
      image: ghcr.io/pcoder7/spider-puredns-actions:latest
      credentials:
        username: ${{ secrets.GHCR_USER }}
        password: ${{ secrets.GHCR_TOKEN }}
    steps:
      - name: Download all recon artifacts
        uses: actions/download-artifact@v4
        with:
          # Download all artifacts into separate directories under 'temp-results'
          pattern: recon-results-*
          path: temp-results/

      - name: Organize and Push to store-recon
        id: Organize-push
        env:
          STORE_RECON_PAT: ${{ secrets.STORE_RECON_PAT }}
          STORE_REPO_OWNER: ${{ secrets.STORE_OWNER }} # IMPORTANT: Change to the owner of store-recon
          STORE_REPO_NAME: ${{ secrets.STORE_REPO_NAME }}
        run: |
          set -e # Exit immediately if a command fails

          if [ ! -d "temp-results" ] || [ -z "$(ls -A temp-results)" ]; then
            echo "No artifacts found to process. Exiting."
            exit 0
          fi

          echo "Cloning the 'store-recon' repository..."
          CLONE_DIR=$(mktemp -d)
          git clone "https://x-access-token:${STORE_RECON_PAT}@github.com/${STORE_REPO_OWNER}/${STORE_REPO_NAME}.git" "$CLONE_DIR"
          cd "$CLONE_DIR"

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Robust retry loop to handle any remote race conditions on the store-recon repo
          for i in {1..10}; do
            # Always start from the freshest state of the remote branch
            git fetch origin main
            git reset --hard origin/main
            git pull origin main --rebase

            echo "Merging new results into the repository..."

            # Iterate through each downloaded artifact directory (e.g., 'temp-results/recon-results-domain1.com')
            for artifact_path in ${GITHUB_WORKSPACE}/temp-results/*; do
              if [ -d "$artifact_path" ]; then
                source_file="$artifact_path/all_subdomains.txt"
                
                # Check if the primary results file exists in the artifact
                if [ -f "$source_file" ]; then
                  # Extract the domain name by removing the 'recon-results-' prefix from the directory name
                  domain=$(basename "$artifact_path" | sed 's/^recon-results-//')
                  
                  # Define the target directory structure as requested: 'results/domain.com/'
                  target_dir="results/$domain"
                  target_file="$target_dir/all_subdomains.txt"

                  echo "Processing results for: $domain"
                  
                  # Create the target directory (e.g., 'results/domain1.com').
                  # 'mkdir -p' will do nothing if the directory already exists. It will not overwrite.
                  mkdir -p "$target_dir"

                  # This is the key command for your requirement:
                  # It reads the new results and appends only the unique, new lines to the target file.
                  # If the target file doesn't exist, 'anew' creates it.
                  cat "$source_file" | anew -q "$target_file"
                fi
              fi
            done

            git add results/

            # Check for changes before committing to avoid empty commits
            if git diff --staged --quiet; then
              echo "No new unique subdomains found. Repository is already up-to-date."
              exit 0
            fi

            echo "Committing updated results..."
            git commit -m "Daily Recon: Update subdomain results (Run: ${{ github.run_id }})"

            if git push origin main; then
              echo "Successfully pushed results to ${STORE_REPO_NAME} on attempt #$i."
              exit 0 # Success!
            else
              echo "Push failed on attempt #$i. Retrying in 15 seconds..."
              sleep 15
            fi
          done

          echo "ERROR: Could not push results to ${STORE_REPO_NAME} after 10 attempts."
          exit 0

 
  trigger_puredns:
    name: Trigger PureDNS Workflow
    needs:  commit_results 
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Trigger PureDNS Workflow using repository_dispatch
        env:
          PAT_TOKEN: ${{ secrets.PAT_TOKEN }}
        id: trigger-puredns  
        run: |
          echo "Triggering the 'Parallel PureDNS Split, Resolve, and Sort' workflow..."
          curl -X POST \
            -H "Accept: application/vnd.github.v3+json" \
            -H "Authorization: token ${PAT_TOKEN}" \
            https://api.github.com/repos/Pcoder7/puredns-res/dispatches \
            -d '{"event_type": "trigger_puredns", "client_payload": {"results_repo": "${{ github.repository }}", "results_dir": "results", "run_id": ${{ github.run_id }} }}'
          
          

